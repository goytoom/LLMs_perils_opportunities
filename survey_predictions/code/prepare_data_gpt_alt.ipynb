{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2b34f8d-c80f-4fb9-ae90-ec0d28b09d8b",
   "metadata": {},
   "source": [
    "This codebook creates multiple alternative prompts to elicit responses to various questionnaires from ChatGPT. Prompts only contain surface level changes in order to test the effect of small changes in prompts to outputs (prompt sensitivity)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db02182e-ab4a-4c33-a4f8-2cb37407230c",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b486622e-2190-42ac-b2aa-f01674b87ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc382f27-6e04-4003-8ef4-b0565f4b0dc6",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ca2dc0-08d5-4c99-ac11-88fad5d59b2e",
   "metadata": {},
   "source": [
    "### General Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa981f5-aa35-41e3-b154-1cb6ec6b383e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FOLDER = \"../data/surveys/\"\n",
    "\n",
    "COLS_META = [\"sex\", \"age\", \"currentCountry\",  \"political_opinion\", \"race\", \n",
    "        \"religion\", \"education\", \"income\", \"social_class\"] \n",
    "\n",
    "# adjust to survey (can have different scales)\n",
    "# more information: Intro about our study, explaining what it is about\n",
    "ALT1 = \"For a scientific study, we are collecting responses to various psychological questionnaires. In the following you will be shown statements from a personality test. Please indicate your level of agreement with each statement. There are no right or wrong answers. Use numbers from 1 to 5, with 1 meaning strongly disagree and 5 meaning strongly agree. Respond with a single number. The statement is: \"\n",
    "\n",
    "# semantics/rephraming, replace as much with synonyms, but kept general sense vague\n",
    "ALT2 = \"For an ongoing research project, please express how much you agree with the statement shown at the end. Respond with an integer between 1 and 5, where 1 indicates a strong disagreement and 5 indicates a strong agreement. Respond with a single digit only. Here's the statement:\"\n",
    "\n",
    "#response values (scale)\n",
    "ALT3 = \"For a scientific study, please indicate your level of agreement with the following statement. Use integer numbers from -2 to 2, with -2 meaning strongly disagree and 2 meaning strongly agree. Respond with a single number. The statement is: \"\n",
    "\n",
    "# also test order of items shown\n",
    "PROMPT_TEXT = \"For a scientific study, please indicate your level of agreement with the following statement. Use integer numbers from 1 to 5, with 1 meaning strongly disagree and 5 meaning strongly agree. Respond with a single number. The statement is: \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b76ef51-fa43-47d9-af0d-8de07d173cb4",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1327c84b-f646-4900-a517-0aebdf0ac2ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extractSurveys(data):\n",
    "    path = FOLDER + data + \".csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    print(set(COLS_META) <= set(df.columns)) # check if meta information is in dataset\n",
    "    \n",
    "    idx = df.columns.tolist().index(\"sex\") #index of last survey item\n",
    "    cols_items = df.columns.tolist()[:idx]\n",
    "    print(cols_items[-1]) # print last survey item\n",
    "    \n",
    "    df_items = df.dropna(subset=cols_items, axis = 0)\n",
    "    df_total = df_items.dropna(subset=COLS_META).reset_index(drop=True)\n",
    "    df_total.to_csv(\"../data/processed/\" + data + \"_cleaned.csv\", index=False)\n",
    "    \n",
    "    item_path = \"../data/items/\" + data + \"_items.csv\"\n",
    "    if not (os.path.isfile(item_path)):\n",
    "        items_list = pd.DataFrame(cols_items)\n",
    "        items_list.to_csv(item_path, index=False)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return df_total, cols_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293756f-22bb-4e19-895b-da5e59d386ff",
   "metadata": {},
   "source": [
    "## BIG5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65396eef-bd11-496b-9617-60c022e9508d",
   "metadata": {},
   "source": [
    "Prompting is tested here only for the BFI but this pipeline can be extended to any survey (simply adapt the prompts for the respective survey andd repeat the analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8fa5efa-37ba-413f-beb3-6757347d6b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1027789/1109698091.py:3: DtypeWarning: Columns (53,63,66) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "bigfive_44\n"
     ]
    }
   ],
   "source": [
    "d = \"bigfive\"\n",
    "df_bigfive, cols_meta_bigfive = extractSurveys(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ce3e72-2d3f-4fb8-8334-ecb60dbc4012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"../data/items/\" + d + \"_items.csv\", sep=\";\")\n",
    "# check the respective texts in the original questionnaires\n",
    "for i, prompt_text in enumerate([ALT1,ALT2,ALT3]):  \n",
    "    prompts = [prompt_text + \"\\\"\" + x + \"\\\"\" for x in items.item_text]\n",
    "    #show prompts\n",
    "    with open(\"../data/prompts/ALT\" + str(i+1) + \"_\" + d + \".pkl\", \"wb\") as output:\n",
    "        pickle.dump(prompts, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
