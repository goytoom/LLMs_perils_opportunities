{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2b34f8d-c80f-4fb9-ae90-ec0d28b09d8b",
   "metadata": {},
   "source": [
    "ADD EXPLANATION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db02182e-ab4a-4c33-a4f8-2cb37407230c",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b486622e-2190-42ac-b2aa-f01674b87ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe729c-86dc-4ccf-a454-0ae8a232d808",
   "metadata": {},
   "source": [
    "Get Meta-Data and store separaetly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc382f27-6e04-4003-8ef4-b0565f4b0dc6",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ca2dc0-08d5-4c99-ac11-88fad5d59b2e",
   "metadata": {},
   "source": [
    "### General Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6fa981f5-aa35-41e3-b154-1cb6ec6b383e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FOLDER = \"../data/surveys/\"\n",
    "\n",
    "COLS_META = [\"sex\", \"age\", \"currentCountry\",  \"political_opinion\", \"race\", \n",
    "        \"religion\", \"education\", \"income\", \"social_class\"] \n",
    "\n",
    "# adjust to survey (can have different scales)\n",
    "# more information: Intro about our study, explaining what it is about\n",
    "ALT1 = \"For a scientific study, we are collecting responses to various psychological questionnaires. In the following you will be shown statements from a personality test. Please indicate your level of agreement with each statement. There are no right or wrong answers. Use numbers from 1 to 5, with 1 meaning strongly disagree and 5 meaning strongly agree. Respond with a single number. The statement is: \"\n",
    "\n",
    "# semantics/rephraming, replace as much with synonyms, but kept general sense vague\n",
    "ALT2 = \"For an ongoing research project, please express how much you agree with the statement shown at the end. Respond with an integer between 1 and 5, where 1 indicates a strong disagreement and 5 indicates a strong agreement. Respond with a single digit only. Here's the statement:\"\n",
    "\n",
    "#response values (scale)\n",
    "ALT4 = \"For a scientific study, please indicate your level of agreement with the following statement. Use integer numbers from -2 to 2, with -2 meaning strongly disagree and 2 meaning strongly agree. Respond with a single number. The statement is: \"\n",
    "\n",
    "# also test order of items shown\n",
    "PROMPT_TEXT = \"For a scientific study, please indicate your level of agreement with the following statement. Use integer numbers from 1 to 5, with 1 meaning strongly disagree and 5 meaning strongly agree. Respond with a single number. The statement is: \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b76ef51-fa43-47d9-af0d-8de07d173cb4",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1327c84b-f646-4900-a517-0aebdf0ac2ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extractSurveys(data):\n",
    "    path = FOLDER + data + \".csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    print(set(COLS_META) <= set(df.columns)) # check if meta information is in dataset\n",
    "    \n",
    "    idx = df.columns.tolist().index(\"sex\") #index of last survey item\n",
    "    cols_items = df.columns.tolist()[:idx]\n",
    "    print(cols_items[-1]) # print last survey item\n",
    "    \n",
    "    df_items = df.dropna(subset=cols_items, axis = 0)\n",
    "    df_total = df_items.dropna(subset=COLS_META).reset_index(drop=True)\n",
    "    df_total.to_csv(\"../data/processed/\" + data + \"_cleaned.csv\", index=False)\n",
    "    \n",
    "    item_path = \"../data/items/\" + data + \"_items.csv\"\n",
    "    if not (os.path.isfile(item_path)):\n",
    "        items_list = pd.DataFrame(cols_items)\n",
    "        items_list.to_csv(item_path, index=False)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return df_total, cols_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "686efa00-3149-49d5-a36f-01f72a85f7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cognition_18\n"
     ]
    }
   ],
   "source": [
    "d = \"cognition\"\n",
    "df_cognition, cols_meta_cognition = extractSurveys(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d20940f7-25e0-4306-9c8a-35b494ad3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"../data/items/\" + d + \"_items.csv\", sep=\";\")\n",
    "# check the respective texts in the original questionnaires\n",
    "prompts = [PROMPT_TEXT + \"\\\"\" + x + \"\\\"\" for x in items.item_text]\n",
    "#show prompts\n",
    "with open(\"../data/prompts/\" + d + \".pkl\", \"wb\") as output:\n",
    "    pickle.dump(prompts, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ed18f-8d1c-4abf-aff4-5459e146a824",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6ee02ac-80ed-424c-b243-372d94a3383e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "closure_16\n"
     ]
    }
   ],
   "source": [
    "d = \"closure\"\n",
    "df_closure, cols_meta_closure = extractSurveys(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ade7a75a-94f6-4283-afd1-164a171aa8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"../data/items/\" + d + \"_items.csv\", sep=\";\")\n",
    "# check the respective texts in the original questionnaires\n",
    "prompts = [PROMPT_TEXT + \"\\\"\" + x + \"\\\"\" for x in items.item_text]\n",
    "#show prompts\n",
    "with open(\"../data/prompts/\" + d + \".pkl\", \"wb\") as output:\n",
    "    pickle.dump(prompts, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "142d6159-d513-45d5-891a-a0e1a4c0c3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For a scientific study, please indicate your level of agreement with the following statement. Use integer numbers from 1 to 6, with 1 meaning strongly disagree and 6 meaning strongly agree. Respond with a single number. The statement is: \"In case of uncertainty, I prefer to make an immediate decision, whatever it may be.\"'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose dataset\n",
    "d = \"closure\"\n",
    "# create path\n",
    "path = \"../data/items/\" + d + \"_items.csv\"\n",
    "path_items = '../data/items/' + d + '_items.csv'\n",
    "\n",
    "with open ('../data/prompts/' + d + \".pkl\", 'rb') as fp:\n",
    "    prompts = pickle.load(fp)\n",
    "    \n",
    "prompts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293756f-22bb-4e19-895b-da5e59d386ff",
   "metadata": {},
   "source": [
    "## BIG5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65396eef-bd11-496b-9617-60c022e9508d",
   "metadata": {},
   "source": [
    "Prompting is tested here only for the BFI but this pipeline can be extended to any survey (simply adapt the prompts for the respective survey andd repeat the analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8fa5efa-37ba-413f-beb3-6757347d6b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhai\\AppData\\Local\\Temp\\ipykernel_16672\\1109698091.py:3: DtypeWarning: Columns (53,63,66) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "bigfive_44\n"
     ]
    }
   ],
   "source": [
    "d = \"bigfive\"\n",
    "df_bigfive, cols_meta_bigfive = extractSurveys(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b0ce3e72-2d3f-4fb8-8334-ecb60dbc4012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"../data/items/\" + d + \"_items.csv\", sep=\";\")\n",
    "# check the respective texts in the original questionnaires\n",
    "for i, prompt_text in enumerate([ALT1,ALT2,ALT3,ALT4,ALT5]):  \n",
    "    prompts = [prompt_text + \"\\\"\" + x + \"\\\"\" for x in items.item_text]\n",
    "    #show prompts\n",
    "    with open(\"../data/prompts/ALT\" + str(i+1) + \"_\" + d + \".pkl\", \"wb\") as output:\n",
    "        pickle.dump(prompts, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45604e7f-0aae-46f6-9904-6cc79db56188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhai\\AppData\\Local\\Temp\\ipykernel_23280\\1109698091.py:3: DtypeWarning: Columns (61,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "systems_feelings_42\n"
     ]
    }
   ],
   "source": [
    "d = \"systems_feelings\"\n",
    "df_systems_feelings, cols_meta_systems_feelings = extractSurveys(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d53e66a-248e-4b39-a8d4-e91e50cb1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"../data/items/\" + d + \"_items.csv\", sep=\";\")\n",
    "# check the respective texts in the original questionnaires\n",
    "prompts = [PROMPT_TEXT + \"\\\"\" + x + \"\\\"\" for x in items.item_text]\n",
    "#show prompts\n",
    "with open(\"../data/prompts/\" + d + \".pkl\", \"wb\") as output:\n",
    "    pickle.dump(prompts, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e0c84e10-34b9-49ca-a1cd-176e2c403aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhai\\AppData\\Local\\Temp\\ipykernel_23280\\1109698091.py:3: DtypeWarning: Columns (59,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cogref_40\n"
     ]
    }
   ],
   "source": [
    "d = \"cogref\"\n",
    "df_cogref, cols_meta_cogref = extractSurveys(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e5fe3b6c-c786-41a8-a330-887756982d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"../data/items/\" + d + \"_items.csv\", sep=\";\")\n",
    "# check the respective texts in the original questionnaires\n",
    "prompts = [PROMPT_TEXT + \"\\\"\" + x + \"\\\"\" for x in items.item_text]\n",
    "#show prompts\n",
    "with open(\"../data/prompts/\" + d + \".pkl\", \"wb\") as output:\n",
    "    pickle.dump(prompts, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
