{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a583d3-3ef9-4cb9-8e0e-8b48bf029255",
   "metadata": {},
   "source": [
    "ADD EXPLANATION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc77c580-4e2f-402d-92c1-a9754d643188",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b486622e-2190-42ac-b2aa-f01674b87ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe729c-86dc-4ccf-a454-0ae8a232d808",
   "metadata": {},
   "source": [
    "Get Meta-Data and store separaetly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc382f27-6e04-4003-8ef4-b0565f4b0dc6",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ca2dc0-08d5-4c99-ac11-88fad5d59b2e",
   "metadata": {},
   "source": [
    "### General Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa981f5-aa35-41e3-b154-1cb6ec6b383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = \"../data/surveys/\"\n",
    "\n",
    "COLS_META = [\"sex\", \"age\", \"currentCountry\",  \"political_opinion\", \"race\", \n",
    "        \"religion\", \"education\", \"income\", \"social_class\"] \n",
    "\n",
    "# adjust to survey (can have different scales)\n",
    "PROMPT_TEXT_1 = \"Indicate your general level of agreement with the following statement: \\\"\\\"\\\"\"\n",
    "PROMPT_TEXT_2 = \"\\\"\\\"\\\"\\nRespond with a single integer between 1 and 5, with 1 meaning \\\"strongly disagree\\\" and 5 meaning \\\"strongly agree\\\". Respond only with this number. Do not respond with words.\\n\\nASSISTANT:\"\n",
    "\n",
    "# define scale endpoints for addition in prompt\n",
    "scale_meaning_dict = {}\n",
    "for key in ['bigfive', 'cogref', 'closure', 'rwa', 'systems_feelings', \"cognition\", \"mfq2\"]:\n",
    "    if key==\"systems_feelings\":\n",
    "        scale_meaning_dict[key] = [\"strongly disagree\", \"strongly agree\", 1, 4] #SCALE end points in word and number\n",
    "    elif key==\"closure\" or key==\"rwa\":\n",
    "        scale_meaning_dict[key] = [\"strongly disagree\", \"strongly agree\", 1, 6]\n",
    "    elif \"cogref\" in key:\n",
    "        scale_meaning_dict[key] = [\"definitely not true of me\", \"definitely true of me\", 1, 5]\n",
    "    else:\n",
    "        scale_meaning_dict[key] = [\"strongly disagree\", \"strongly agree\", 1, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b76ef51-fa43-47d9-af0d-8de07d173cb4",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1327c84b-f646-4900-a517-0aebdf0ac2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSurveys(data):\n",
    "    path = FOLDER + data + \".csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    print(set(COLS_META) <= set(df.columns)) # check if meta information is in dataset\n",
    "    \n",
    "    idx = df.columns.tolist().index(\"sex\") #index of last survey item\n",
    "    cols_items = df.columns.tolist()[:idx]\n",
    "    print(cols_items[-1]) # print last survey item\n",
    "    \n",
    "    df_items = df.dropna(subset=cols_items, axis = 0)\n",
    "    df_total = df_items.dropna(subset=COLS_META).reset_index(drop=True)\n",
    "    df_total.to_csv(\"../data/processed/\" + data + \"_cleaned_llama2.csv\", index=False)\n",
    "    print(df_total.shape)\n",
    "\n",
    "    return df_total, cols_items\n",
    "\n",
    "def generatePrompts(d):\n",
    "    items = pd.read_csv(\"../data/items/\" + d + \"_items.csv\", sep=\";\")\n",
    "    texts = items.item_text.tolist()\n",
    "    meaning_min, meaning_max, min_val, max_val = scale_meaning_dict[d]\n",
    "    prompts = [\"\"\"USER: You will indicate your general level of agreement with a statement given to you. You will express your level of agreement as an integer between {} and {}, with {} meaning \\\"{}\\\" and {} meaning \\\"{}\\\". You will respond with nothing but this number. How much do you agree with this statement? \\\"\\\"\\\" {} \\\"\\\"\\\"\n",
    "\n",
    "ASSISTANT:\"\"\".format(min_val, max_val, min_val, meaning_min, max_val, meaning_max, text) for text in texts]\n",
    "    return prompts\n",
    "\n",
    "def extractPrompts(d):\n",
    "    with open ('../data/prompts/' + d + \"_llama2.pkl\", 'rb') as fp:\n",
    "        prompts = pickle.load(fp)\n",
    "    items = pd.read_csv(\"../data/items/\" + d + \"_items.csv\", sep=\";\")\n",
    "    return prompts, items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d71e699-4c06-4a35-a034-eefa260cd538",
   "metadata": {},
   "source": [
    "## Test Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f04be980-ac3a-428d-997b-570c5a4932cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @retry(delay=5)\n",
    "def run(prompt, verbose=0, slow_down=0.001):\n",
    "    request = {\n",
    "        'prompt': prompt,\n",
    "        'max_new_tokens': 150,\n",
    "        'mode' : 'instruct',\n",
    "\n",
    "        # Generation params. If 'preset' is set to different than 'None', the values\n",
    "        # in presets/preset-name.yaml are used instead of the individual numbers.\n",
    "        'preset': \"None\", #'simple-1',\n",
    "        'do_sample': True,\n",
    "        'temperature': 0.76,\n",
    "        'top_p': 0.9,\n",
    "        'typical_p': 1,\n",
    "        'epsilon_cutoff': 0,  # In units of 1e-4\n",
    "        'eta_cutoff': 0,  # In units of 1e-4\n",
    "        'tfs': 1,\n",
    "        'top_a': 0,\n",
    "        'repetition_penalty': 1.15,\n",
    "        'repetition_penalty_range': 0,\n",
    "        'encoder_repetition_penalty': 1,\n",
    "        'top_k': 20,\n",
    "        'min_length': 0,\n",
    "        'no_repeat_ngram_size': 0,\n",
    "        'num_beams': 1,\n",
    "        'penalty_alpha': 0,\n",
    "        'length_penalty': 1,\n",
    "        'early_stopping': False,\n",
    "        'mirostat_mode': 0,\n",
    "        'mirostat_tau': 5,\n",
    "        'mirostat_eta': 0.1,\n",
    "        # 'instruction_template': \"Instruct-Alpaca\",\n",
    "\n",
    "        'seed': -1,\n",
    "        'add_bos_token': True,\n",
    "        'truncation_length': 2048,\n",
    "        'ban_eos_token': False,\n",
    "        'skip_special_tokens': True,\n",
    "        'stopping_strings': []\n",
    "    }\n",
    "\n",
    "    response = requests.post(URI, json=request)\n",
    "\n",
    "    if response.status_code == 200 and verbose == 1:\n",
    "        result = response.json()['results'][0]['text']\n",
    "        print(prompt + result)\n",
    "    # time.sleep(slow_down)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8352e25b-8222-4c39-9ce3-76e19c495451",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = generatePrompts(\"cognition\")\n",
    "test_prompt = prompts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f7dddebf-dff1-4ff0-aa4a-266de8599ac6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: You will indicate your general level of agreement with a statement given to you. You will express your level of agreement as an integer between 1 and 5, with 1 meaning \"strongly disagree\" and 5 meaning \"strongly agree\". You will respond with nothing but this number. How much do you agree with this statement? \"\"\" I like to have the responsibility of handling a situation that requires a lot of thinking. \"\"\"\n",
      "\n",
      "ASSISTANT: 4\n",
      "USER: You will indicate your general level of agreement with a statement given to you. You will express your level of agreement as an integer between 1 and 5, with 1 meaning \"strongly disagree\" and 5 meaning \"strongly agree\". You will respond with nothing but this number. How much do you agree with this statement? \"\"\" I like to have the responsibility of handling a situation that requires a lot of thinking. \"\"\"\n",
      "\n",
      "ASSISTANT: 3\n",
      "USER: You will indicate your general level of agreement with a statement given to you. You will express your level of agreement as an integer between 1 and 5, with 1 meaning \"strongly disagree\" and 5 meaning \"strongly agree\". You will respond with nothing but this number. How much do you agree with this statement? \"\"\" I like to have the responsibility of handling a situation that requires a lot of thinking. \"\"\"\n",
      "\n",
      "ASSISTANT: 4\n",
      "USER: You will indicate your general level of agreement with a statement given to you. You will express your level of agreement as an integer between 1 and 5, with 1 meaning \"strongly disagree\" and 5 meaning \"strongly agree\". You will respond with nothing but this number. How much do you agree with this statement? \"\"\" I like to have the responsibility of handling a situation that requires a lot of thinking. \"\"\"\n",
      "\n",
      "ASSISTANT: 3\n",
      "USER: You will indicate your general level of agreement with a statement given to you. You will express your level of agreement as an integer between 1 and 5, with 1 meaning \"strongly disagree\" and 5 meaning \"strongly agree\". You will respond with nothing but this number. How much do you agree with this statement? \"\"\" I like to have the responsibility of handling a situation that requires a lot of thinking. \"\"\"\n",
      "\n",
      "ASSISTANT: 4\n",
      "USER: You will indicate your general level of agreement with a statement given to you. You will express your level of agreement as an integer between 1 and 5, with 1 meaning \"strongly disagree\" and 5 meaning \"strongly agree\". You will respond with nothing but this number. How much do you agree with this statement? \"\"\" I like to have the responsibility of handling a situation that requires a lot of thinking. \"\"\"\n",
      "\n",
      "ASSISTANT: 4\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "HOST = 'localhost:5000'\n",
    "URI = f'http://{HOST}/api/v1/generate'\n",
    "\n",
    "test_answer = run(test_prompt, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24dc321-52fc-44bd-8b68-e6dbb6c505c7",
   "metadata": {},
   "source": [
    "## Need for Cognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "686efa00-3149-49d5-a36f-01f72a85f7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cognition_18\n",
      "(900, 53)\n"
     ]
    }
   ],
   "source": [
    "d = \"cognition\"\n",
    "df_cognition, cols_meta_cognition = extractSurveys(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d20940f7-25e0-4306-9c8a-35b494ad3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"cognition\"\n",
    "prompts = generatePrompts(d)\n",
    "#show prompts\n",
    "with open(\"../data/prompts/\" + d + \"_llama2.pkl\", \"wb\") as output:\n",
    "    pickle.dump(prompts, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ed18f-8d1c-4abf-aff4-5459e146a824",
   "metadata": {},
   "source": [
    "## Closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6ee02ac-80ed-424c-b243-372d94a3383e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "closure_16\n",
      "(315, 51)\n"
     ]
    }
   ],
   "source": [
    "d = \"closure\"\n",
    "df_closure, cols_meta_closure = extractSurveys(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ade7a75a-94f6-4283-afd1-164a171aa8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"closure\"\n",
    "prompts = generatePrompts(d)\n",
    "#show prompts\n",
    "with open(\"../data/prompts/\" + d + \"_llama2.pkl\", \"wb\") as output:\n",
    "    pickle.dump(prompts, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293756f-22bb-4e19-895b-da5e59d386ff",
   "metadata": {},
   "source": [
    "## BIG5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8fa5efa-37ba-413f-beb3-6757347d6b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhai\\AppData\\Local\\Temp\\ipykernel_15140\\130783463.py:3: DtypeWarning: Columns (53,63,66) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "bigfive_44\n",
      "(3924, 79)\n"
     ]
    }
   ],
   "source": [
    "d = \"bigfive\"\n",
    "df_bigfive, cols_meta_bigfive = extractSurveys(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b0ce3e72-2d3f-4fb8-8334-ecb60dbc4012",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"bigfive\"\n",
    "prompts = generatePrompts(d)\n",
    "#show prompts\n",
    "with open(\"../data/prompts/\" + d + \"_llama2.pkl\", \"wb\") as output:\n",
    "    pickle.dump(prompts, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6f0006-1b54-4d4d-928f-57e6072915db",
   "metadata": {},
   "source": [
    "## RWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1246d274-4528-497a-9e1c-2438649ebf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "rwa_15\n",
      "(1020, 50)\n"
     ]
    }
   ],
   "source": [
    "d = \"rwa\"\n",
    "df_rwa, cols_meta_rwa = extractSurveys(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "30db6f97-7584-4d91-b34a-113888159f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"rwa\"\n",
    "prompts = generatePrompts(d)\n",
    "#show prompts\n",
    "with open(\"../data/prompts/\" + d + \"_llama2.pkl\", \"wb\") as output:\n",
    "    pickle.dump(prompts, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a6b34-9102-4dd4-b06a-f3fdf47b0960",
   "metadata": {},
   "source": [
    "## Systems & Feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45604e7f-0aae-46f6-9904-6cc79db56188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "systems_feelings_42\n",
      "(3141, 77)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhai\\AppData\\Local\\Temp\\ipykernel_15140\\130783463.py:3: DtypeWarning: Columns (61,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    }
   ],
   "source": [
    "d = \"systems_feelings\"\n",
    "df_systems_feelings, cols_meta_systems_feelings = extractSurveys(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4d53e66a-248e-4b39-a8d4-e91e50cb1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"systems_feelings\"\n",
    "prompts = generatePrompts(d)\n",
    "#show prompts\n",
    "with open(\"../data/prompts/\" + d + \"_llama2.pkl\", \"wb\") as output:\n",
    "    pickle.dump(prompts, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ebe00-46cc-41eb-8692-1446504a02a4",
   "metadata": {},
   "source": [
    "## Cognitive Style Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0c84e10-34b9-49ca-a1cd-176e2c403aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cogref_40\n",
      "(1456, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhai\\AppData\\Local\\Temp\\ipykernel_15140\\130783463.py:3: DtypeWarning: Columns (59,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    }
   ],
   "source": [
    "d = \"cogref\"\n",
    "df_cogref, cols_meta_cogref = extractSurveys(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e5fe3b6c-c786-41a8-a330-887756982d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"cogref\"\n",
    "prompts = generatePrompts(d)\n",
    "#show prompts\n",
    "with open(\"../data/prompts/\" + d + \"_llama2.pkl\", \"wb\") as output:\n",
    "    pickle.dump(prompts, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
