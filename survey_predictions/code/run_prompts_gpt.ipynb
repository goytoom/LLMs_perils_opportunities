{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de6f65a-04cb-4b0d-aa7b-f7a99da73329",
   "metadata": {},
   "source": [
    "This codebook collects ChatGPT's responses to a diverse range of questionnaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a0540e-8bde-4d03-a650-822a70a41d67",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b6c84d-9d8e-4209-bf35-36fadd958c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import logging\n",
    "from retry import retry\n",
    "logging.basicConfig()\n",
    "\n",
    "# Calculate the delay based on your rate limit\n",
    "rate_limit_per_minute = 3500.0\n",
    "delay = 60.0 / rate_limit_per_minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b2e19-804e-4369-bf4f-45a3572d7684",
   "metadata": {},
   "source": [
    "## Define chatgpt calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea3c1a-bafa-47b0-9464-e514acca5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general parameters\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") # add your api key to the environment\n",
    "model_engine = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "070b133c-6afe-49d7-98ea-b9dc220f1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(delay=5)\n",
    "def delayed_completion(delay_in_seconds: float = 1, **kwargs):\n",
    "    \"\"\"Delay a completion by a specified amount of time.\"\"\"\n",
    "\n",
    "    # Sleep for the delay\n",
    "    time.sleep(delay_in_seconds)\n",
    "\n",
    "    # Call the Completion API and return the result\n",
    "    return openai.ChatCompletion.create(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e409f-916c-44ba-a47d-1e6db6131fc7",
   "metadata": {},
   "source": [
    "## Test Prompts and Test ChatGPT call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6841722-a276-43ff-b51f-55d07ae70573",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Test Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb06575e-7cc4-4106-9f86-9382f3386d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose dataset\n",
    "d = \"closure\" # change to respecticve dataset name\n",
    "# create path\n",
    "path = \"../data/items/\" + d + \"_items.csv\"\n",
    "path_items = '../data/items/' + d + '_items.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3812c3da-1135-41d7-8bf5-c385e5a3e637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open ('../data/prompts/' + d + \".pkl\", 'rb') as fp:\n",
    "    prompts = pickle.load(fp)\n",
    "    \n",
    "items = pd.read_csv(path_items, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "063ef705-9778-4f7d-a686-74d849cec466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': 'For a scientific study, please indicate your level of agreement with the following statement. Use integer numbers from 1 to 6, with 1 meaning strongly disagree and 6 meaning strongly agree. Respond with a single number. The statement is: \"I feel uncomfortable when I do not manage to give a quick response to problems that I face.\"'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": x} for x in prompts]\n",
    "test_prompt = messages[10]\n",
    "test_prompt # check test before running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c42956-dfd3-4edc-9780-ebcbf924006c",
   "metadata": {},
   "source": [
    "## Test API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "694afc57-dd39-4e63-a403-3c46e413c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "APIresponse = delayed_completion(\n",
    "    delay_in_seconds=delay,\n",
    "    model=model_engine,\n",
    "    messages=[test_prompt],\n",
    "    temperature=1\n",
    "    )\n",
    "response = APIresponse.choices[0].message[\"content\"]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc297f61-4de1-48ca-8e0c-a29f644b0211",
   "metadata": {},
   "source": [
    "## Run chatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa65ec8a-aee7-4890-9281-e9af493188d4",
   "metadata": {},
   "source": [
    "Define list of surveys to collect responses on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff4ba56-36b1-425f-bbd0-ec08a6c0dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = [\"bigfive\", \"cognition\", \"closure\", \"systems_feelings\", \"rwa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff4d19-e9be-490f-8cb0-5611cf8fda0d",
   "metadata": {},
   "source": [
    "### Run calls\n",
    "NOTE: This will charge your account. Check the current openai prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "626be96a-bc9a-4c39-8ba9-9b45161ddb95",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_1\n",
      "response_2\n",
      "response_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:retry.api:That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 02bff6598e062c4366614b760ab93acd in your message.), retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_4\n",
      "response_5\n",
      "response_6\n",
      "response_7\n",
      "response_8\n",
      "response_9\n",
      "response_10\n",
      "response_11\n",
      "response_12\n",
      "response_13\n",
      "response_14\n",
      "response_15\n",
      "response_16\n",
      "response_17\n",
      "response_18\n",
      "response_19\n",
      "response_20\n",
      "response_21\n",
      "response_22\n",
      "response_23\n",
      "response_24\n",
      "response_25\n",
      "response_26\n",
      "response_27\n",
      "response_28\n",
      "response_29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:retry.api:That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3b8eef94c1e6cc3ff3f9cf7c633b42cb in your message.), retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_30\n",
      "response_31\n",
      "response_32\n",
      "response_33\n",
      "response_34\n",
      "response_35\n",
      "response_36\n",
      "response_37\n",
      "response_38\n",
      "response_39\n",
      "response_40\n",
      "response_41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:retry.api:That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 15801e5bec1ec8e18cbc5a37e29a479c in your message.), retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_42\n",
      "response_43\n",
      "response_44\n",
      "response_45\n",
      "response_46\n",
      "response_47\n",
      "response_48\n",
      "response_49\n",
      "response_50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:retry.api:The server had an error while processing your request. Sorry about that!, retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_51\n",
      "response_52\n",
      "response_53\n",
      "response_54\n",
      "response_55\n",
      "response_56\n",
      "response_57\n",
      "response_58\n",
      "response_59\n",
      "response_60\n",
      "response_61\n",
      "response_62\n",
      "response_63\n",
      "response_64\n",
      "response_65\n",
      "response_66\n",
      "response_67\n",
      "response_68\n",
      "response_69\n",
      "response_70\n",
      "response_71\n",
      "response_72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:retry.api:That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5185663f09d3f66272e41ecc6d1979a0 in your message.), retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_73\n",
      "response_74\n",
      "response_75\n",
      "response_76\n",
      "response_77\n",
      "response_78\n",
      "response_79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:retry.api:That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8b8e2484a95d009a2efce69af4a614b4 in your message.), retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_80\n",
      "response_81\n",
      "response_82\n",
      "response_83\n",
      "response_84\n",
      "response_85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:retry.api:That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID af02d1aebb6de8605db926a4b0c5bebd in your message.), retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_86\n",
      "response_87\n",
      "response_88\n",
      "response_89\n",
      "response_90\n",
      "response_91\n",
      "response_92\n",
      "response_93\n",
      "response_94\n",
      "response_95\n",
      "response_96\n",
      "response_97\n",
      "response_98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:retry.api:That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ac9de3ba2deab7969ee355f0a6f5b78f in your message.), retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:retry.api:That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 25b4a085fc9ad7cbca2bf5ba783f76cd in your message.), retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_100\n"
     ]
    }
   ],
   "source": [
    "for d in d_list: # iterate over dataset\n",
    "    \n",
    "    # create path\n",
    "    path = \"../data/items/\" + d + \"_items.csv\"\n",
    "    path_items = '../data/items/' + d + '_items.csv'\n",
    "    \n",
    "    #load prompts\n",
    "    with open ('../data/prompts/' + d + \".pkl\", 'rb') as fp:\n",
    "        prompts = pickle.load(fp)\n",
    "    items = pd.read_csv(path_items, sep=\";\")\n",
    "    \n",
    "    #create inputs for API from prompts\n",
    "    messages = [{\"role\": \"user\", \"content\": x} for x in prompts]\n",
    "    \n",
    "    repeats = 100\n",
    "    total_responses = []\n",
    "    for i in range(repeats):\n",
    "        col_name = \"response_\" + str(i+1)\n",
    "        print(col_name)\n",
    "        responses = []\n",
    "        for i, message in enumerate(messages):\n",
    "            APIresponse = delayed_completion(\n",
    "                delay_in_seconds=delay,\n",
    "                model=model_engine,\n",
    "                messages=[message],\n",
    "                temperature=1,\n",
    "                )\n",
    "            response = APIresponse.choices[0].message[\"content\"]\n",
    "            responses.append(response)\n",
    "        total_responses.append(responses)\n",
    "\n",
    "    # save as dataframe\n",
    "    new_dic = {}\n",
    "    new_dic[\"id\"] = items.id.tolist()\n",
    "    new_dic[\"item_text\"] = items.item_text.tolist()\n",
    "    for i, values in enumerate(total_responses):\n",
    "        new_dic[f'response_{i+1}'] = values\n",
    "    df_responses = pd.DataFrame(new_dic)\n",
    "    df_responses.to_csv(\"../results/\" + d + \".csv\", index=False) #save ChatGPT results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
