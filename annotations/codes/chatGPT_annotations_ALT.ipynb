{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd468764-85ce-4cb6-8ca3-49700cfb1fb8",
   "metadata": {},
   "source": [
    "This code book calls the OpenAI API to classify moral sentiments in posts from the Moral Foundations Reddit Corpus using ChatGPT!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91abfc0-abfb-4374-a408-6a09fe36c14b",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca7c26cf-9783-4ba8-b0c2-79a8a2d5c4e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "import re\n",
    "remove = string.punctuation\n",
    "remove = remove.replace(\"-\", \"\").replace(\",\", \"\") # don't remove hyphens\n",
    "pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import logging\n",
    "from retry import retry\n",
    "logging.basicConfig()\n",
    "\n",
    "# Calculate the delay based on your rate limit\n",
    "rate_limit_per_minute = 3500.0\n",
    "delay_60 = 60.0 / 60\n",
    "delay_full = 60.0 / rate_limit_per_minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572d4601-a181-4fc0-9ff0-efb3f0d8b0ff",
   "metadata": {},
   "source": [
    "## General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e40c53c4-f26c-4dc7-babe-39cb77569822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = \"mfrc\"\n",
    "mode = \"full\"\n",
    "folder = \"../data/preprocessed/\"\n",
    "path = folder + data + \"_sample_\" + mode + \".csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99e6b8-baea-42dc-8467-dafcd97472b8",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8410c23-d642-40ea-bb96-b6392c4aeec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chatGPT parameters\n",
    "openai.api_key = \"\" #add your openai key here\n",
    "model_engine = \"gpt-3.5-turbo-0301\"\n",
    "\n",
    "@retry(delay=5)\n",
    "def delayed_completion(delay_in_seconds: float = 1, **kwargs):\n",
    "    \"\"\"Delay a completion by a specified amount of time.\"\"\"\n",
    "\n",
    "    # Sleep for the delay\n",
    "    time.sleep(delay_in_seconds)\n",
    "\n",
    "    # Call the Completion API and return the result\n",
    "    return openai.ChatCompletion.create(**kwargs)\n",
    "\n",
    "def separate_labels(df, cols):\n",
    "    def _set_labels(row):\n",
    "        for label in row[\"annotations\"].split(\",\"):\n",
    "            if label in cols:\n",
    "                row[label.strip()] = 1\n",
    "        return row\n",
    "\n",
    "    # removing texts with no annotations\n",
    "    df = df[df.annotations != ''].reset_index(drop=True)\n",
    "    df = df[~ pd.isna(df.annotations)].reset_index(drop=True)\n",
    "    for label in cols:\n",
    "        df[label] = 0\n",
    "    df = df.apply(_set_labels, axis=1).drop([\"annotations\"], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75469f4-5b5f-4463-bef5-1f325d533c7d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51954440-8bbd-4181-8149-8103dd72292e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#change order of examples\n",
    "ALT1 = \"Which of these moral sentiments best represents the following text?\" \\\n",
    "\"\\\"purity\\\" if the text is about avoiding bodily and spiritual contamination and degradation, \"\\\n",
    "\"\\\"equality\\\" if the text is about equal treatment and equal outcome for individuals, \" \\\n",
    "\"\\\"authority\\\" if the text is about deference toward legitimate authorities and the defense of traditions, \"\\\n",
    "\"all of which are seen as providing stability and fending off chaos, \"\\\n",
    "\"\\\"thin morality\\\" if the text has a moral sentiment but cannot be categorized as either of these categories, \"\\\n",
    "\"\\\"loyalty\\\" if the text is about cooperating with ingroups and competing with outgroups, \"\\\n",
    "\"\\\"proportionality\\\" if the text is about individuals getting rewarded in proportion to their merit or contribution, \"\\\n",
    "\"\\\"care\\\" if the text is about avoiding emotional and physical damage to another individual. \" \\\n",
    "\"Respond only with these words. Respond with any of the categories that apply, comma separated. Here is the text: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6caedb6f-8cf5-40e9-a03a-cf8b9682b54b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2983, 9)\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "prompt_style = \"ALT1\" # change if you have different/multiple prompts\n",
    "# \"ALT1\": alternative prompt 1 (for prompt sensitivity study)\n",
    "\n",
    "if prompt_style == \"ALT1\":\n",
    "    # load annotation texts\n",
    "    df = pd.read_csv(path)\n",
    "    print(df.shape)\n",
    "    print(round(df.text.str.split(\"\\\\s+\").str.len().mean()))\n",
    "    messages = [{\"role\": \"user\", \"content\": ALT1 + x} for x in df.text]\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d9776-c62e-448d-a7a7-f4cab94b15dd",
   "metadata": {},
   "source": [
    "## Test Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5ece223-9a5b-40b4-9f79-542e14540337",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': 'Which of these moral sentiments best represents the following text?\"purity\" if the text is about avoiding bodily and spiritual contamination and degradation, \"equality\" if the text is about equal treatment and equal outcome for individuals, \"authority\" if the text is about deference toward legitimate authorities and the defense of traditions, all of which are seen as providing stability and fending off chaos, \"thin morality\" if the text has a moral sentiment but cannot be categorized as either of these categories, \"loyalty\" if the text is about cooperating with ingroups and competing with outgroups, \"proportionality\" if the text is about individuals getting rewarded in proportion to their merit or contribution, \"care\" if the text is about avoiding emotional and physical damage to another individual. Respond only with these words. Respond with any of the categories that apply, comma separated. Here is the text: Was just browsing r/Politics, noticed [this tired old trope](https://www.reddit.com/r/politics/comments/6goce7/bernie_sanders_says_labour_party_shows_the_way_to/dirtr7d/) rearing it\\'s ugly head. DAE Macron is actually left for American politics?'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "52250c34-9345-4845-9042-8c772c56e102",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thin morality\n"
     ]
    }
   ],
   "source": [
    "APIresponse = delayed_completion(\n",
    "    delay_in_seconds=delay_full,\n",
    "    model=model_engine,\n",
    "    messages=[messages[10]],\n",
    "    temperature=0\n",
    "    )\n",
    "response = APIresponse.choices[0].message[\"content\"]\n",
    "print(response) #works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce67b9f-4dbc-4ffb-9e66-bbf82f6881f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a5c57ca5-e53a-4bef-bce8-db79611d7536",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n",
      "WARNING:retry.api:The server is overloaded or not ready yet., retrying in 5 seconds...\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "for i, message in enumerate(messages):\n",
    "    APIresponse = delayed_completion(\n",
    "        delay_in_seconds=delay_full,\n",
    "        model=model_engine,\n",
    "        messages=[message],\n",
    "        temperature=0,\n",
    "        )\n",
    "    response = APIresponse.choices[0].message[\"content\"]\n",
    "    responses.append(response)\n",
    "\n",
    "# clean gpt outputs (for predictions that have imprecise wording, e.g., none for non-moral)\n",
    "responses_cleaned = [re.sub(pattern, \"\", x.lower()) if \"none\" not in x.lower() else \"non-moral\" for x in responses]\n",
    "\n",
    "# save as dataframe\n",
    "new_dic = {}\n",
    "new_dic[\"text\"] = df.text.tolist()\n",
    "new_dic[\"annotations\"] = responses_cleaned\n",
    "df_responses = pd.DataFrame(new_dic)\n",
    "\n",
    "cols = df.columns[1:].tolist()\n",
    "df_preds = separate_labels(df_responses, cols)\n",
    "df_preds.to_csv(\"../results/predictions/gpt_\" + data + \"_labels_\" + mode + \"_\" + prompt_style + \".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
