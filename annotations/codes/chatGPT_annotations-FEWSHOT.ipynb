{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd468764-85ce-4cb6-8ca3-49700cfb1fb8",
   "metadata": {},
   "source": [
    "This code book calls the OpenAI API to classify moral sentiments in posts from the Moral Foundations Reddit Corpus using ChatGPT (Fewshot)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91abfc0-abfb-4374-a408-6a09fe36c14b",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca7c26cf-9783-4ba8-b0c2-79a8a2d5c4e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "import re\n",
    "remove = string.punctuation\n",
    "remove = remove.replace(\"-\", \"\").replace(\",\", \"\") # don't remove hyphens\n",
    "pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import logging\n",
    "from retry import retry\n",
    "logging.basicConfig()\n",
    "\n",
    "# Calculate the delay based on your rate limit\n",
    "rate_limit_per_minute = 3500.0\n",
    "delay_60 = 60.0 / 60\n",
    "delay_full = 60.0 / rate_limit_per_minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572d4601-a181-4fc0-9ff0-efb3f0d8b0ff",
   "metadata": {},
   "source": [
    "## General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40c53c4-f26c-4dc7-babe-39cb77569822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = \"mfrc\"\n",
    "mode = \"full\"\n",
    "folder = \"../data/preprocessed/\"\n",
    "path = folder + data + \"_sample_\" + mode + \".csv\"\n",
    "path_train = folder + data + \"_train_\" + mode + \".csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75469f4-5b5f-4463-bef5-1f325d533c7d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af463866-e3e4-42d3-8c88-92b586160195",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5db0478e-a32b-4dbf-9d64-c6131704c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompts(definitions, examples, test_texts):\n",
    "    prompts = {}\n",
    "        \n",
    "    for foundation, definition in definitions.items():\n",
    "        full_instruction = \"Determine the presence of \\\"{}\\\" in the following text. The text contains \\\"{}\\\" {}. Respond with \\\"yes\\\" if the sentiment is expressed in the text and \\\"no\\\" if it is not. Respond only with a single word and do not elaborate. Here is the text: \".format(foundation, foundation, definition)\n",
    "        short_instruction = \"Determine the presence of the moral sentiment of '{}' in the following text: \".format(foundation)\n",
    "        \n",
    "        example_texts = examples[foundation]\n",
    "        messages = [{\"role\": \"system\", \"content\": SYSTEM_INSTR}]\n",
    "        \n",
    "        # For the first example, we use the full instruction\n",
    "        first_example_text = example_texts[0]\n",
    "        user_message = {\"role\": \"user\", \"content\": full_instruction + first_example_text}\n",
    "        assistant_message = {\"role\": \"assistant\", \"content\": \"yes\"}\n",
    "        messages.extend([user_message, assistant_message])\n",
    "        \n",
    "        # For subsequent examples, we use the shortened instruction\n",
    "        for text in example_texts[1:]:\n",
    "            user_message = {\"role\": \"user\", \"content\": short_instruction + text}\n",
    "            assistant_message = {\"role\": \"assistant\", \"content\": \"yes\"}\n",
    "            messages.extend([user_message, assistant_message])\n",
    "\n",
    "        # For the test texts, we also use the shortened instruction\n",
    "        for test_text in test_texts:\n",
    "            user_test_message = {\"role\": \"user\", \"content\": short_instruction + test_text}\n",
    "            full_prompt = {\"messages\": messages + [user_test_message]}\n",
    "            prompts.setdefault(foundation, []).append(full_prompt)\n",
    "\n",
    "    return prompts\n",
    "\n",
    "# System role instructions\n",
    "SYSTEM_INSTR = \"Detect the presence of a moral sentiment in a text based on its provided definition.\"\n",
    "\n",
    "FOUNDATIONS_DEFINITIONS = {\n",
    "    \"care\": \"if it is about avoiding emotional and physical damage to another individual\",\n",
    "    \"equality\": \"if it is about equal treatment and equal outcome for individuals.\",\n",
    "    \"proportionality\": \"if it is about individuals getting rewarded in proportion to their merit or contribution\",\n",
    "    \"loyalty\": \"if it is about cooperating with ingroups and competing with outgroups\",\n",
    "    \"authority\": \"if it is about deference toward legitimate authorities and the defense of traditions, all of which are seen as providing stability and fending off chaos\",\n",
    "    \"purity\": \"if it is about avoiding bodily and spiritual contamination and degradation\",\n",
    "    \"thin morality\": \"if it has a moral sentiment but cannot be categorized as a specific moral value\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d59c82-df59-41c2-8b9d-98d7ebc9a185",
   "metadata": {},
   "source": [
    "### Generate Example Prompts for Fewshot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6a4b2e-e02f-402b-b4a3-826f9907202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "df_train = pd.read_csv(path_train)\n",
    "df_test = pd.read_csv(path)\n",
    "test_texts = df_test.text.tolist()\n",
    "\n",
    "# create multiple df for each foundation\n",
    "df_dict = {} # store training data for each prediction class here\n",
    "for pred_class in df_train.columns[1:]: # separate data for each output\n",
    "    df_dict[pred_class] = df_train[[\"text\", pred_class]]\n",
    "pred_classes = list(df_train.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee5aad0d-bd0a-4459-9f18-985aca708e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample and manually validate 2 good examples\n",
    "# other examples: care | equality| proportionality | loyalty | authority | purity | thin morality | non-moral |\n",
    "# 3, 12, | 2, 18 | 6, 13, 14, 15 | 1, 3, 8 | 4, 7 | 6, 7, 9 | 0, 1, 6 | 10, 11, 17|\n",
    "# find examples in df_df_dict\n",
    "idx_dict = {\"care\": [25, 31], \"equality\": [10, 16], \"proportionality\": [12,  17], \"loyalty\": [0, 2], \n",
    "                 \"authority\": [1, 3], \"purity\": [0, 3], \"thin morality\": [2, 4], \"non-moral\": [1, 16]}\n",
    "ex_dict = {key: np.array(df_train[(df_train[key] == 1) & (df_train.sum(1) == 1)].text.iloc[idx]) for key, idx in idx_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebca1eb0-2368-4410-8fed-108ebc1f7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate Prompts\n",
    "prompts = generate_prompts(FOUNDATIONS_DEFINITIONS, ex_dict, test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aab9898-eb46-4c7f-aad2-5174ee60c826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'Detect the presence of a moral sentiment in a text based on its provided definition.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Determine the presence of \"care\" in the following text. The text contains \"care\" if it is about avoiding emotional and physical damage to another individual. Respond with \"yes\" if the sentiment is expressed in the text and \"no\" if it is not. Respond only with a single word and do not elaborate. Here is the text: &gt;she basically abused\\n\\nItâ€™s more like she literally abused him by depriving him of what constitutes a *limb*.'},\n",
       " {'role': 'assistant', 'content': 'yes'},\n",
       " {'role': 'user',\n",
       "  'content': \"Determine the presence of the moral sentiment of 'care' in the following text: 100% NTA. It absolutely is your place to get involved if you suspect animal abuse. If there is an explanation this will be uncovered and no real harm done except the owner may be a bit peeved. Alternatively, if they shouldn't be owning a dog, you'll be putting an animal into a much nicer situation away from the cruelty/ abuse.\"},\n",
       " {'role': 'assistant', 'content': 'yes'},\n",
       " {'role': 'user',\n",
       "  'content': \"Determine the presence of the moral sentiment of 'care' in the following text: 1. That's\\n2. Why\\n3. Macron\\n4. Won\\n5. Bitch\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check prompts\n",
    "prompts[\"care\"][0][\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99e6b8-baea-42dc-8467-dafcd97472b8",
   "metadata": {},
   "source": [
    "## API Call Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8410c23-d642-40ea-bb96-b6392c4aeec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chatGPT parameters\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") # add your api key to the environment\n",
    "model_engine = \"gpt-3.5-turbo-0301\"\n",
    "\n",
    "@retry(delay=5)\n",
    "def delayed_completion(delay_in_seconds: float = 1, **kwargs):\n",
    "    \"\"\"Delay a completion by a specified amount of time.\"\"\"\n",
    "\n",
    "    # Sleep for the delay\n",
    "    time.sleep(delay_in_seconds)\n",
    "\n",
    "    # Call the Completion API and return the result\n",
    "    return openai.ChatCompletion.create(**kwargs)\n",
    "\n",
    "def clean_response(x):\n",
    "    return 1 if \"yes\" in x else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d9776-c62e-448d-a7a7-f4cab94b15dd",
   "metadata": {},
   "source": [
    "## Test Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52250c34-9345-4845-9042-8c772c56e102",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test all foundations with the first example\n",
    "for foundation, test_calls in prompts.items():\n",
    "    test_call = test_calls[0][\"messages\"]\n",
    "    print(foundation)\n",
    "    print(test_call)\n",
    "    APIresponse = delayed_completion(\n",
    "        delay_in_seconds=delay_full,\n",
    "        model=model_engine,\n",
    "        messages=test_call,\n",
    "        temperature=0\n",
    "        )\n",
    "    response = APIresponse.choices[0].message[\"content\"]\n",
    "    print(response) #works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154297e7-9640-46ab-bb17-ee874c6d5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a single example\n",
    "test_call = prompts[\"purity\"][61][\"messages\"]\n",
    "print(test_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c31367-5270-4256-a554-69a59734dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_call)\n",
    "APIresponse = delayed_completion(\n",
    "    delay_in_seconds=delay_full,\n",
    "    model=model_engine,\n",
    "    messages=test_call,\n",
    "    temperature=0\n",
    "    )\n",
    "response = APIresponse.choices[0].message[\"content\"]\n",
    "print(response) #works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce67b9f-4dbc-4ffb-9e66-bbf82f6881f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86e13a06-120f-495b-a804-6549911704ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\\%\n",
      "9\\%\n",
      "19\\%\n",
      "29\\%\n",
      "39\\%\n",
      "49\\%\n",
      "59\\%\n",
      "69\\%\n",
      "79\\%\n",
      "89\\%\n",
      "99\\%\n",
      "0\\%\n",
      "9\\%\n",
      "19\\%\n",
      "29\\%\n",
      "39\\%\n",
      "49\\%\n",
      "59\\%\n",
      "69\\%\n",
      "79\\%\n",
      "89\\%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:retry.api:Rate limit reached for gpt-3.5-turbo-0301 in organization org-yVS6iCwS4TFCckmhlIwrbL8m on tokens per min. Limit: 90000 / min. Current: 89577 / min. Contact us through our help center at help.openai.com if you continue to have issues., retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\\%\n",
      "0\\%\n",
      "9\\%\n",
      "19\\%\n",
      "29\\%\n",
      "39\\%\n",
      "49\\%\n",
      "59\\%\n",
      "69\\%\n",
      "79\\%\n",
      "89\\%\n",
      "99\\%\n",
      "0\\%\n",
      "9\\%\n",
      "19\\%\n",
      "29\\%\n",
      "39\\%\n",
      "49\\%\n",
      "59\\%\n",
      "69\\%\n",
      "79\\%\n",
      "89\\%\n",
      "99\\%\n",
      "0\\%\n",
      "9\\%\n",
      "19\\%\n",
      "29\\%\n",
      "39\\%\n",
      "49\\%\n",
      "59\\%\n",
      "69\\%\n",
      "79\\%\n",
      "89\\%\n",
      "99\\%\n",
      "0\\%\n",
      "9\\%\n",
      "19\\%\n",
      "29\\%\n",
      "39\\%\n",
      "49\\%\n",
      "59\\%\n",
      "69\\%\n",
      "79\\%\n",
      "89\\%\n",
      "99\\%\n",
      "0\\%\n",
      "9\\%\n",
      "19\\%\n",
      "29\\%\n",
      "39\\%\n",
      "49\\%\n",
      "59\\%\n",
      "69\\%\n",
      "79\\%\n",
      "89\\%\n",
      "99\\%\n"
     ]
    }
   ],
   "source": [
    "new_dic = {}\n",
    "new_dic[\"text\"] = test_texts\n",
    "\n",
    "for foundation, prompt_list in prompts.items():\n",
    "    responses = []\n",
    "    print(foundation)\n",
    "    for i, prompt in enumerate(prompt_list):\n",
    "        APIresponse = delayed_completion(\n",
    "            delay_in_seconds=delay_full,\n",
    "            model=model_engine,\n",
    "            messages=prompt[\"messages\"],\n",
    "            temperature=0,\n",
    "            )\n",
    "        response = APIresponse.choices[0].message[\"content\"]\n",
    "        responses.append(response)\n",
    "        if not i % int(0.1 * len(prompt_list)):\n",
    "            print(str(int(i/len(prompt_list)*100)) + \"\\%\")\n",
    "    new_dic[foundation] = responses\n",
    "    df_temp = pd.DataFrame(new_dic)\n",
    "    df_temp.to_csv(\"../results/predictions/gpt_fewshot_\" + data + \"_labels_\" + foundation + \"_\" + mode + \".csv\", index=False)\n",
    "\n",
    "# clean responses and save in final dataset\n",
    "df_responses = pd.DataFrame(new_dic)\n",
    "cols_to_clean = df_responses.columns[df_responses.columns != 'text']\n",
    "df_responses[cols_to_clean] = df_responses[cols_to_clean].applymap(clean_response)\n",
    "df_responses[\"non-moral\"] = (df_responses.drop(columns=['text']).sum(axis=1) == 0).astype(int) # non-moral if no moral sentiment found\n",
    "df_responses.to_csv(\"../results/predictions/gpt_fewshot_\" + data + \"_labels_\" + mode + \".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
