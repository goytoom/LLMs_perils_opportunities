{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd468764-85ce-4cb6-8ca3-49700cfb1fb8",
   "metadata": {},
   "source": [
    "This code book calls the OpenAI API to classify moral sentiments in posts from the Moral Foundations Reddit Corpus using ChatGPT!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91abfc0-abfb-4374-a408-6a09fe36c14b",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca7c26cf-9783-4ba8-b0c2-79a8a2d5c4e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "import re\n",
    "remove = string.punctuation\n",
    "remove = remove.replace(\"-\", \"\").replace(\",\", \"\") # don't remove hyphens\n",
    "pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import logging\n",
    "from retry import retry\n",
    "logging.basicConfig()\n",
    "\n",
    "# Calculate the delay based on your rate limit\n",
    "rate_limit_per_minute = 3500.0\n",
    "delay_60 = 60.0 / 60\n",
    "delay_full = 60.0 / rate_limit_per_minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572d4601-a181-4fc0-9ff0-efb3f0d8b0ff",
   "metadata": {},
   "source": [
    "## General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40c53c4-f26c-4dc7-babe-39cb77569822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = \"mfrc\"\n",
    "mode = \"full\"\n",
    "folder = \"../data/preprocessed/\"\n",
    "path = folder + data + \"_sample_\" + mode + \".csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99e6b8-baea-42dc-8467-dafcd97472b8",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8410c23-d642-40ea-bb96-b6392c4aeec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chatGPT parameters\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") # add your api key to the environment\n",
    "model_engine = \"gpt-3.5-turbo-0301\"\n",
    "\n",
    "@retry(delay=5)\n",
    "def delayed_completion(delay_in_seconds: float = 1, **kwargs):\n",
    "    \"\"\"Delay a completion by a specified amount of time.\"\"\"\n",
    "\n",
    "    # Sleep for the delay\n",
    "    time.sleep(delay_in_seconds)\n",
    "\n",
    "    # Call the Completion API and return the result\n",
    "    return openai.ChatCompletion.create(**kwargs)\n",
    "\n",
    "def separate_labels(df, cols):\n",
    "    def _set_labels(row):\n",
    "        for label in row[\"annotations\"].split(\",\"):\n",
    "            if label in cols:\n",
    "                row[label.strip()] = 1\n",
    "        return row\n",
    "\n",
    "    # removing texts with no annotations\n",
    "    df = df[df.annotations != ''].reset_index(drop=True)\n",
    "    df = df[~ pd.isna(df.annotations)].reset_index(drop=True)\n",
    "    for label in cols:\n",
    "        df[label] = 0\n",
    "    df = df.apply(_set_labels, axis=1).drop([\"annotations\"], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75469f4-5b5f-4463-bef5-1f325d533c7d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51954440-8bbd-4181-8149-8103dd72292e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create general prompt\n",
    "PROMPT_TEXT = \"Determine which moral sentiments are expressed in the following text. \" \\\n",
    "\"\\\"care\\\" if the text is about avoiding emotional and physical damage to another individual, \" \\\n",
    "\"\\\"equality\\\" if the text is about equal treatment and equal outcome for individuals, \" \\\n",
    "\"\\\"proportionality\\\" if the text is about individuals getting rewarded in proportion to their merit or contribution, \"\\\n",
    "\"\\\"loyalty\\\" if the text is about cooperating with ingroups and competing with outgroups, \"\\\n",
    "\"\\\"authority\\\" if the text is about deference toward legitimate authorities and the defense of traditions, \"\\\n",
    "\"all of which are seen as providing stability and fending off chaos, \"\\\n",
    "\"\\\"purity\\\" if the text is about avoiding bodily and spiritual contamination and degradation, \"\\\n",
    "\"\\\"thin morality\\\" if the text has a moral sentiment but cannot be categorized as either of the above, \"\\\n",
    "\"\\\"non-moral\\\" if no moral sentiment is expressed in the text. \"\\\n",
    "\"Respond only with these words. Respond with all words that apply, comma separated. Here is the text: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd822b6e-7bbf-4920-8fe5-678d5118e5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Determine which moral sentiments are expressed in the following text. \"care\" if the text is about avoiding emotional and physical damage to another individual, \"equality\" if the text is about equal treatment and equal outcome for individuals, \"proportionality\" if the text is about individuals getting rewarded in proportion to their merit or contribution, \"loyalty\" if the text is about cooperating with ingroups and competing with outgroups, \"authority\" if the text is about deference toward legitimate authorities and the defense of traditions, all of which are seen as providing stability and fending off chaos, \"purity\" if the text is about avoiding bodily and spiritual contamination and degradation, \"thin morality\" if the text has a moral sentiment but cannot be categorized as either of the above, \"non-moral\" if no moral sentiment is expressed in the text. Respond only with these words. Respond with all words that apply, comma separated. Here is the text: '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check prompt\n",
    "PROMPT_TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6caedb6f-8cf5-40e9-a03a-cf8b9682b54b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2983, 9)\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "# load annotation texts\n",
    "df = pd.read_csv(path)\n",
    "print(df.shape)\n",
    "print(round(df.text.str.split(\"\\\\s+\").str.len().mean()))\n",
    "messages = [{\"role\": \"user\", \"content\": PROMPT_TEXT + x} for x in df.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d9776-c62e-448d-a7a7-f4cab94b15dd",
   "metadata": {},
   "source": [
    "## Test Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ece223-9a5b-40b4-9f79-542e14540337",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': 'Determine which moral sentiments are expressed in the following text. \"care\" if the text is about avoiding emotional and physical damage to another individual, \"equality\" if the text is about equal treatment and equal outcome for individuals, \"proportionality\" if the text is about individuals getting rewarded in proportion to their merit or contribution, \"loyalty\" if the text is about cooperating with ingroups and competing with outgroups, \"authority\" if the text is about deference toward legitimate authorities and the defense of traditions, all of which are seen as providing stability and fending off chaos, \"purity\" if the text is about avoiding bodily and spiritual contamination and degradation, \"thin morality\" if the text has a moral sentiment but cannot be categorized as either of the above, \"non-moral\" if no moral sentiment is expressed in the text. Respond only with these words. Respond with all words that apply, comma separated. Here is the text: Was just browsing r/Politics, noticed [this tired old trope](https://www.reddit.com/r/politics/comments/6goce7/bernie_sanders_says_labour_party_shows_the_way_to/dirtr7d/) rearing it\\'s ugly head. DAE Macron is actually left for American politics?'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check test prompt\n",
    "messages[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52250c34-9345-4845-9042-8c772c56e102",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thin morality\n"
     ]
    }
   ],
   "source": [
    "# run test api call\n",
    "APIresponse = delayed_completion(\n",
    "    delay_in_seconds=delay_full,\n",
    "    model=model_engine,\n",
    "    messages=[messages[10]],\n",
    "    temperature=0\n",
    "    )\n",
    "response = APIresponse.choices[0].message[\"content\"]\n",
    "print(response) #works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce67b9f-4dbc-4ffb-9e66-bbf82f6881f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5c57ca5-e53a-4bef-bce8-db79611d7536",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\\%\n",
      "9\\%\n",
      "19\\%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:retry.api:Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 23 Oct 2023 18:31:19 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '81abffc20c2e52ef-LAX', 'alt-svc': 'h3=\":443\"; ma=86400'}, retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\\%\n",
      "39\\%\n",
      "49\\%\n",
      "59\\%\n",
      "69\\%\n",
      "79\\%\n",
      "89\\%\n",
      "99\\%\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "for i, message in enumerate(messages):\n",
    "    APIresponse = delayed_completion(\n",
    "        delay_in_seconds=delay_full,\n",
    "        model=model_engine,\n",
    "        messages=[message],\n",
    "        temperature=0,\n",
    "        )\n",
    "    response = APIresponse.choices[0].message[\"content\"]\n",
    "    responses.append(response)\n",
    "    if not i % int(0.1 * len(messages)):\n",
    "        print(str(int(i/len(messages)*100)) + \"\\%\")\n",
    "\n",
    "# clean gpt outputs (for predictions that have imprecise wording, e.g., none for non-moral)\n",
    "responses_cleaned = [re.sub(pattern, \"\", x.lower()) if \"none\" not in x.lower() else \"non-moral\" for x in responses]\n",
    "\n",
    "# save as dataframe\n",
    "new_dic = {}\n",
    "new_dic[\"text\"] = df.text.tolist()\n",
    "new_dic[\"annotations\"] = responses_cleaned\n",
    "df_responses = pd.DataFrame(new_dic)\n",
    "\n",
    "cols = df.columns[1:].tolist()\n",
    "df_preds = separate_labels(df_responses, cols)\n",
    "df_preds.to_csv(\"../results/predictions/gpt_\" + data + \"_labels_\" + mode + \".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
