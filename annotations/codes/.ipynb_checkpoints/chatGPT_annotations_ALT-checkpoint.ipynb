{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd468764-85ce-4cb6-8ca3-49700cfb1fb8",
   "metadata": {},
   "source": [
    "This code book calls the OpenAI API to classify moral sentiments in posts from the Moral Foundations Reddit Corpus using ChatGPT!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91abfc0-abfb-4374-a408-6a09fe36c14b",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca7c26cf-9783-4ba8-b0c2-79a8a2d5c4e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "import re\n",
    "remove = string.punctuation\n",
    "remove = remove.replace(\"-\", \"\").replace(\",\", \"\") # don't remove hyphens\n",
    "pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import logging\n",
    "from retry import retry\n",
    "logging.basicConfig()\n",
    "\n",
    "# Calculate the delay based on your rate limit\n",
    "rate_limit_per_minute = 3500.0\n",
    "delay_60 = 60.0 / 60\n",
    "delay_full = 60.0 / rate_limit_per_minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572d4601-a181-4fc0-9ff0-efb3f0d8b0ff",
   "metadata": {},
   "source": [
    "## General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40c53c4-f26c-4dc7-babe-39cb77569822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = \"mfrc\"\n",
    "mode = \"full\"\n",
    "folder = \"../data/preprocessed/\"\n",
    "path = folder + data + \"_sample_\" + mode + \".csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99e6b8-baea-42dc-8467-dafcd97472b8",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8410c23-d642-40ea-bb96-b6392c4aeec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chatGPT parameters\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") # add your api key to the environment\n",
    "model_engine = \"gpt-3.5-turbo-0301\"\n",
    "\n",
    "@retry(delay=5)\n",
    "def delayed_completion(delay_in_seconds: float = 1, **kwargs):\n",
    "    \"\"\"Delay a completion by a specified amount of time.\"\"\"\n",
    "\n",
    "    # Sleep for the delay\n",
    "    time.sleep(delay_in_seconds)\n",
    "\n",
    "    # Call the Completion API and return the result\n",
    "    return openai.ChatCompletion.create(**kwargs)\n",
    "\n",
    "def separate_labels(df, cols):\n",
    "    def _set_labels(row):\n",
    "        for label in row[\"annotations\"].split(\",\"):\n",
    "            if label in cols:\n",
    "                row[label.strip()] = 1\n",
    "        return row\n",
    "\n",
    "    # removing texts with no annotations\n",
    "    df = df[df.annotations != ''].reset_index(drop=True)\n",
    "    df = df[~ pd.isna(df.annotations)].reset_index(drop=True)\n",
    "    for label in cols:\n",
    "        df[label] = 0\n",
    "    df = df.apply(_set_labels, axis=1).drop([\"annotations\"], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75469f4-5b5f-4463-bef5-1f325d533c7d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51954440-8bbd-4181-8149-8103dd72292e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#change order of examples\n",
    "ALT1 = \"Determine which moral sentiments are expressed in the following text. \" \\\n",
    "\"\\\"purity\\\" if the text is about avoiding bodily and spiritual contamination and degradation, \"\\\n",
    "\"\\\"equality\\\" if the text is about equal treatment and equal outcome for individuals, \" \\\n",
    "\"\\\"authority\\\" if the text is about deference toward legitimate authorities and the defense of traditions, \"\\\n",
    "\"all of which are seen as providing stability and fending off chaos, \"\\\n",
    "\"\\\"thin morality\\\" if the text has a moral sentiment but cannot be categorized as either of these categories, \"\\\n",
    "\"\\\"loyalty\\\" if the text is about cooperating with ingroups and competing with outgroups, \"\\\n",
    "\"\\\"proportionality\\\" if the text is about individuals getting rewarded in proportion to their merit or contribution, \"\\\n",
    "\"\\\"non-moral\\\" if no moral sentiment is expressed in the text, \" \\\n",
    "\"\\\"care\\\" if the text is about avoiding emotional and physical damage to another individual. \" \\\n",
    "\"Respond only with these words. Respond with any of the categories that apply, comma separated. Here is the text: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6caedb6f-8cf5-40e9-a03a-cf8b9682b54b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2983, 9)\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "prompt_style = \"ALT1\" # change if you have different/multiple prompts\n",
    "# \"ALT1\": alternative prompt 1 (for prompt sensitivity study)\n",
    "\n",
    "if prompt_style == \"ALT1\":\n",
    "    # load annotation texts\n",
    "    df = pd.read_csv(path)\n",
    "    print(df.shape)\n",
    "    print(round(df.text.str.split(\"\\\\s+\").str.len().mean()))\n",
    "    messages = [{\"role\": \"user\", \"content\": ALT1 + x} for x in df.text]\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d9776-c62e-448d-a7a7-f4cab94b15dd",
   "metadata": {},
   "source": [
    "## Test Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ece223-9a5b-40b4-9f79-542e14540337",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': 'Determine which moral sentiments are expressed in the following text. \"purity\" if the text is about avoiding bodily and spiritual contamination and degradation, \"equality\" if the text is about equal treatment and equal outcome for individuals, \"authority\" if the text is about deference toward legitimate authorities and the defense of traditions, all of which are seen as providing stability and fending off chaos, \"thin morality\" if the text has a moral sentiment but cannot be categorized as either of these categories, \"loyalty\" if the text is about cooperating with ingroups and competing with outgroups, \"proportionality\" if the text is about individuals getting rewarded in proportion to their merit or contribution, \"non-moral\" if no moral sentiment is expressed in the text, \"care\" if the text is about avoiding emotional and physical damage to another individual. Respond only with these words. Respond with any of the categories that apply, comma separated. Here is the text: Was just browsing r/Politics, noticed [this tired old trope](https://www.reddit.com/r/politics/comments/6goce7/bernie_sanders_says_labour_party_shows_the_way_to/dirtr7d/) rearing it\\'s ugly head. DAE Macron is actually left for American politics?'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52250c34-9345-4845-9042-8c772c56e102",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thin morality, care\n"
     ]
    }
   ],
   "source": [
    "APIresponse = delayed_completion(\n",
    "    delay_in_seconds=delay_full,\n",
    "    model=model_engine,\n",
    "    messages=[messages[10]],\n",
    "    temperature=0\n",
    "    )\n",
    "response = APIresponse.choices[0].message[\"content\"]\n",
    "print(response) #works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce67b9f-4dbc-4ffb-9e66-bbf82f6881f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c57ca5-e53a-4bef-bce8-db79611d7536",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\\%\n",
      "9\\%\n",
      "19\\%\n",
      "29\\%\n",
      "39\\%\n",
      "49\\%\n",
      "59\\%\n",
      "69\\%\n",
      "79\\%\n",
      "89\\%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:retry.api:Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 23 Oct 2023 19:14:04 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '81ac3e65ef175325-LAX', 'alt-svc': 'h3=\":443\"; ma=86400'}, retrying in 5 seconds...\n",
      "WARNING:retry.api:Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 23 Oct 2023 19:25:37 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '81ac4f4d2f94dbd1-LAX', 'alt-svc': 'h3=\":443\"; ma=86400'}, retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\\%\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "for i, message in enumerate(messages):\n",
    "    APIresponse = delayed_completion(\n",
    "        delay_in_seconds=delay_full,\n",
    "        model=model_engine,\n",
    "        messages=[message],\n",
    "        temperature=0,\n",
    "        )\n",
    "    response = APIresponse.choices[0].message[\"content\"]\n",
    "    responses.append(response)\n",
    "    if not i % int(0.1 * len(messages)):\n",
    "        print(str(int(i/len(messages)*100)) + \"\\%\")\n",
    "\n",
    "# clean gpt outputs (for predictions that have imprecise wording, e.g., none for non-moral)\n",
    "responses_cleaned = [re.sub(pattern, \"\", x.lower()) if \"none\" not in x.lower() else \"non-moral\" for x in responses]\n",
    "\n",
    "# save as dataframe\n",
    "new_dic = {}\n",
    "new_dic[\"text\"] = df.text.tolist()\n",
    "new_dic[\"annotations\"] = responses_cleaned\n",
    "df_responses = pd.DataFrame(new_dic)\n",
    "\n",
    "cols = df.columns[1:].tolist()\n",
    "df_preds = separate_labels(df_responses, cols)\n",
    "df_preds.to_csv(\"../results/predictions/gpt_\" + data + \"_labels_\" + mode + \"_\" + prompt_style + \".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
