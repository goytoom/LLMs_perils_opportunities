{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f0e2c4-a3e3-49de-be1f-12c94af0a6b3",
   "metadata": {},
   "source": [
    "This codebook extracts LIWC embeddings and trains a simple classifier to predict moral sentiment  \n",
    "The parameter estimation/tuning can take some time on slower machines (~30min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2371f9-191a-40a0-8330-e1f8b018990a",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "8ccec441-464b-4b1e-abf6-72d9c58083af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import subprocess\n",
    "\n",
    "foundations = {\"mfrc\":  {\n",
    "                    \"complete\": [\"care\", \"harm\", \"equality\", \"proportionality\", \"loyalty\", \"betrayal\", \"authority\", \"subversion\", \"purity\", \"degradation\", \"thin morality\", \"non-moral\"],\n",
    "                    \"binding\": [\"individual\", \"binding\", \"proportionality\", \"thin morality\", \"non-moral\"], \n",
    "                    \"moral\": [\"moral\", \"thin morality\", \"non-moral\"],\n",
    "                    \"full\": [\"care\", \"proportionality\", \"loyalty\", \"authority\", \"purity\", \"equality\", \"thin morality\", \"non-moral\"]\n",
    "               }\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c002d5d-2d54-4ab6-98a6-2abdd6620dc1",
   "metadata": {},
   "source": [
    "## Functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "628b61f4-47da-4c29-866d-0a2ccec0fa88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_liwc(input_file, output_file):\n",
    "\n",
    "    cmd_to_execute = [\"LIWC-22-cli\",\n",
    "                  \"--mode\", \"wc\",\n",
    "                  \"--input\", input_file,\n",
    "                  \"--column-indices\", \"1\",\n",
    "                  \"--output\", output_file]\n",
    "\n",
    "    subprocess.call(cmd_to_execute)\n",
    "\n",
    "def train(mode, input_file, label_path, params, model):\n",
    "    \n",
    "    X = pd.read_csv(input_file, index_col=0).drop([\"Segment\"], axis=1) # load liwc vectors\n",
    "    Y = pd.read_csv(label_path).loc[:, foundations[\"mfrc\"][\"full\"]] # extract labels \n",
    "\n",
    "    # loop over N classes and fit classifier for each\n",
    "    for i in range(Y.shape[1]):\n",
    "        c = foundations[\"mfrc\"][\"full\"][i]\n",
    "        y = Y.iloc[:, i]\n",
    "        print(\"Start training: \" + c)\n",
    "        model.set_params(**params[i]).fit(X, y)\n",
    "        print(\"Saving the model\")\n",
    "        pkl.dump(model, open(\"../models/liwc_\" + c + \"_\" + mode + \".sav\", 'wb'))\n",
    "\n",
    "def crossVal(mode, input_file, label_path, model):\n",
    "       \n",
    "    df_train = pd.read_csv(input_file) # load liwc vectors and y\n",
    "    df_labels = pd.read_csv(label_path)\n",
    "    X = pd.read_csv(input_file, index_col=0).drop([\"Segment\"], axis=1) # load liwc vectors\n",
    "    Y = pd.read_csv(label_path).loc[:, foundations[\"mfrc\"][\"full\"]] # extract labels \n",
    "\n",
    "    # loop over N classes and fit classifier for each\n",
    "    # switch to gridsearch + cv\n",
    "    params = []\n",
    "    macro_score = []\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    params_SVC = {'C': [10**x for x in range(-3,4)], # parameter tuning can be improved with more sophisticated methods (here only find regularization)\n",
    "                  'random_state': [0],\n",
    "                  \"gamma\": [\"scale\", \"auto\"],\n",
    "                }\n",
    "\n",
    "    for i in range(Y.shape[1]):\n",
    "        c = Y.columns[i]\n",
    "        y = Y.iloc[:, i]\n",
    "        clf = GridSearchCV(model, params_SVC, cv=cv, scoring=\"f1_macro\")\n",
    "        clf.fit(X, y)\n",
    "        \n",
    "        best_mean_metric = clf.cv_results_['mean_test_score'][clf.best_index_]\n",
    "        best_std_metric = clf.cv_results_['std_test_score'][clf.best_index_]\n",
    "        macro_score.append(best_mean_metric)\n",
    "        print(\"Average CV metric: %.2f\" % (best_mean_metric*100))\n",
    "        print(\"Standard deviation of CV metric: %.2f\" % (best_std_metric))  \n",
    "        params.append(clf.best_params_) #save params for each label\n",
    "            \n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(macro_score), np.std(macro_score)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea78f415-c96f-4052-a9ef-e8d556f89c70",
   "metadata": {},
   "source": [
    "## General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d43a9276-36a2-4efb-b307-4adbc41b62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose MFRC as corpus (can be changed to run on other corpora as necessary)\n",
    "# choose to run on full MFT dimensions (see prepare_data for different ways of categorizing the moral values)\n",
    "# Choose between training=eval for determining train/validation accuracy (e.g., when optimizing parameters) and training=normal to train the model\n",
    "\n",
    "corp = \"mfrc\"\n",
    "mode = \"full\"\n",
    "training = \"normal\"\n",
    "\n",
    "# set location of training files (input features and labels)\n",
    "label_file = \"../data/preprocessed/mfrc_train_full.csv\"\n",
    "liwc_file = \"../data/preprocessed/mfrc_train_\" + mode +  \"_liwc.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0346d88e-f98a-4ec6-9ae3-a692d2f6bfbb",
   "metadata": {},
   "source": [
    "## Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "b9f32ed3-939b-4974-b7ae-8ff13edc14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_liwc(input_file, ouput_file) # extract liwc features (or use LIWC client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbbbdbd-5b77-4fc1-8ac8-7fd1723ffb2e",
   "metadata": {},
   "source": [
    "## Train/Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac355a5-34d6-4cb1-a3a6-d426e95265d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC() # replace with model of choice (e.g., SVC, logistic regression, neural network)\n",
    "best_params = crossVal(mode, liwc_file, label_file, model) ### Find best parameters for a given model using CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a48a11a-f522-468c-af5a-5deba0d0964e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = SVC() # replace with best performing model (e.g., logistic regression)\n",
    "train(mode, liwc_file, raw_file, best_params, model)  ### train model using best parameters on all data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
