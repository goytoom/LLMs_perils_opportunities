{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f0e2c4-a3e3-49de-be1f-12c94af0a6b3",
   "metadata": {},
   "source": [
    "This codebook trains and fine-tunes a BERT model to predict moral sentiment  \n",
    "This can be very slow depending on hardware.  \n",
    "We used a v100, 32GB of RAM, 8 CPUS  \n",
    "However, this code should be able to run on a system with 16GB of RAM, a dedicated GPU (we tested it on a RTX 2070s), and a 6-core CPU (e.g., Ryzen 5 3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2371f9-191a-40a0-8330-e1f8b018990a",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ccec441-464b-4b1e-abf6-72d9c58083af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 23:48:46.134977: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-05 23:48:46.158467: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-05 23:48:46.509148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sabdurah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import load_model \n",
    "from keras.metrics import Precision, Recall\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import tokenization\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "foundations = {\"mfrc\":  {\n",
    "                    \"complete\": [\"care\", \"harm\", \"equality\", \"proportionality\", \"loyalty\", \"betrayal\", \"authority\", \"subversion\", \"purity\", \"degradation\", \"thin morality\", \"non-moral\"],\n",
    "                    \"binding\": [\"individual\", \"binding\", \"proportionality\", \"thin morality\", \"non-moral\"], \n",
    "                    \"moral\": [\"moral\", \"thin morality\", \"non-moral\"],\n",
    "                    \"full\": [\"care\", \"proportionality\", \"loyalty\", \"authority\", \"purity\", \"equality\", \"thin morality\", \"non-moral\"]\n",
    "               }\n",
    "              }\n",
    "classes = {\"mfrc\": {\"full\": 8, \"moral\": 3, \"binding\": 5, \"complete\": 12}}\n",
    "activation = {\"full\": \"sigmoid\", \"moral\": \"sigmoid\", \"binding\": \"sigmoid\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c002d5d-2d54-4ab6-98a6-2abdd6620dc1",
   "metadata": {},
   "source": [
    "## Functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628b61f4-47da-4c29-866d-0a2ccec0fa88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 23:48:47.559379: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-05 23:48:47.586796: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-05 23:48:47.586837: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-05 23:48:47.587494: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-05 23:48:47.587531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-05 23:48:47.587552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-05 23:48:47.963989: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-05 23:48:47.964052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-05 23:48:47.964057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-09-05 23:48:47.964083: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-05 23:48:47.964103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20545 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "def build_model(bert_layer, max_len=512, classes = 5, activation = \"sigmoid\"):\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    outputs= bert_layer(dict(input_word_ids=input_word_ids,\n",
    "    input_mask=input_mask,\n",
    "    input_type_ids=segment_ids))\n",
    "\n",
    "    sequence_output=outputs[\"sequence_output\"]\n",
    "\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    out = tf.keras.layers.Dense(classes, activation=activation)(clf_output)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "                  loss='binary_crossentropy', metrics=[Precision(), Recall()])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def get_binary(_y, threshold):\n",
    "    y = _y.copy()\n",
    "    y[y >= threshold] = 1\n",
    "    y[y < threshold] = 0\n",
    "    return y\n",
    "\n",
    "def F1Measure(y_true, y_pred, threshold=0.5):\n",
    "    y_binary = get_binary(y_pred, threshold)\n",
    "    score = f1_score(y_true, y_binary, average = \"macro\")   \n",
    "\n",
    "    return score\n",
    "\n",
    "def train(mode, bert_layer, corp):\n",
    "    \n",
    "    model = build_model(bert_layer, max_len=256, classes = classes[corp][mode], activation = activation[mode])\n",
    "\n",
    "    with open(\"../data/train_test/\" + corp + \"_train_\" + mode + \".pkl\", \"rb\") as f:\n",
    "        X_train, y_train = pkl.load(f)\n",
    "\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint('../models/' + corp + \"_\" + training + \"_\" + mode + '.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "    print(\"start training\")\n",
    "    t = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=0.1,\n",
    "        epochs=200,\n",
    "        callbacks=[checkpoint, earlystopping],\n",
    "        batch_size=32, #32 works best so far\n",
    "        verbose=1)\n",
    "    print(\"Saving the model\")\n",
    "\n",
    "def crossVal(mode, threshold):\n",
    "       \n",
    "    with open(\"../data/train_test/\" + corp + \"_train_\" + mode + \".pkl\", \"rb\") as f:\n",
    "        X, y = pkl.load(f)\n",
    "\n",
    "    model_file = '../models/' + corp + '_' + training + \"_\" + mode + '_cv.h5'\n",
    "\n",
    "    print(\"Start Cross-Validation\")\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "    cvscores = []\n",
    "    for train, test in kfold.split(X[0], reverse_onehot(y)): #potentially use CV folds as predictions to evaluate against chatGPT\n",
    "        tf.keras.backend.clear_session() # remove any past model from session\n",
    "        if os.path.isfile(model_file): # remove saved models from checkpoint\n",
    "            os.remove(model_file)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        bert_layer = hub.KerasLayer(module_url, trainable=True)\n",
    "        model = build_model(bert_layer, max_len=256, classes = classes[corp][mode], activation = activation[mode])\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(model_file, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "        earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "        \n",
    "        X_train_cv = (X[0][train], X[1][train], X[2][train])\n",
    "        y_train_cv = tf.gather(y, train)\n",
    "        X_test_cv = (X[0][test], X[1][test], X[2][test])\n",
    "        y_test_cv = tf.gather(y, test)\n",
    "        t = model.fit(\n",
    "            X_train_cv, y_train_cv,\n",
    "            validation_data = (X_test_cv, y_test_cv),\n",
    "            epochs=200,\n",
    "            callbacks=[checkpoint, earlystopping],\n",
    "            batch_size=32, #32 works best so far\n",
    "            verbose=1)\n",
    "\n",
    "        #load best model from training\n",
    "        tf.keras.backend.clear_session() \n",
    "        model = load_model(model_file, compile=True, custom_objects={\"KerasLayer\": bert_layer})\n",
    "        y_pred_val = model.predict(X_test_cv)\n",
    "        score = F1Measure(y_test_cv, y_pred_val, threshold)\n",
    "        cvscores.append(score * 100)\n",
    "        print(\"%s: %.2f%%\" % (\"F1-Score (macro average)\", score*100))\n",
    "        \n",
    "        score2 = f1_score(y_test_cv, get_binary(y_pred_val, threshold), average=None)\n",
    "        print(score2.round(3)*100)        \n",
    "        \n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "\n",
    "def reverse_onehot(onehot_data):\n",
    "    # onehot_data assumed to be channel last\n",
    "    data_copy = np.zeros(onehot_data.shape[:-1])\n",
    "    for c in range(onehot_data.shape[-1]):\n",
    "        img_c = onehot_data[..., c]\n",
    "        data_copy[img_c == 1] = c\n",
    "    return data_copy\n",
    "    \n",
    "module_url = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/2\"\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea78f415-c96f-4052-a9ef-e8d556f89c70",
   "metadata": {},
   "source": [
    "## General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43a9276-36a2-4efb-b307-4adbc41b62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose MFRC as corpus (can be changed to run on other corpora as necessary)\n",
    "# choose to run on full MFT dimensions (see prepare_data for different ways of categorizing the moral values)\n",
    "# Choose between training=eval for determining train/validation accuracy and training=normal to train the model\n",
    "\n",
    "corp = \"mfrc\"\n",
    "mode = \"full\"\n",
    "training = \"normal\"\n",
    "threshold = 0.3 #change this value when using eval (decision rule for classification; can impact accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbbbdbd-5b77-4fc1-8ac8-7fd1723ffb2e",
   "metadata": {},
   "source": [
    "## Train/Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8c691-cce9-4e34-820a-a011e9e109d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if training == \"eval\": # determine best model using CV\n",
    "    crossVal(mode, threshold)\n",
    "elif training == \"normal\": # regular training for test sample (against chatGPT)\n",
    "    train(mode, bert_layer, corp)\n",
    "else:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
